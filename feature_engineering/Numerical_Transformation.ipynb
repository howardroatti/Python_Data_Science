{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns_to_use = ['Type', 'Method', 'Regionname', 'Rooms', 'Distance', \n",
    "                  'Postcode', 'Bedroom2', 'Bathroom', 'Landsize', 'Lattitude',\n",
    "                 'Longtitude', 'Propertycount','Price']\n",
    "\n",
    "df_melbourne = pd.read_csv(\"../../Kaggle/Melbourne-House-Snapshot/melb_data.csv\", usecols=columns_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melbourne.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melbourne.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds) #Quanto Menor, Melhor!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separa Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df_melbourne.Price\n",
    "X = df_melbourne.drop(['Price'], axis=1)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recuperando Lista de Variáveis Numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variáveis Numéricos:\n",
      "['Rooms', 'Price', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude', 'Propertycount']\n"
     ]
    }
   ],
   "source": [
    "lista = (df_melbourne.dtypes != 'object')\n",
    "numerical_cols = list(lista[lista].index)\n",
    "\n",
    "print(\"Variáveis Numéricos:\")\n",
    "print(numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recupera colunas categóricas e transforma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variáveis Categóricas:\n",
      "['Type', 'Method', 'Regionname']\n"
     ]
    }
   ],
   "source": [
    "#Trata atributos categóricos\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "s = (df_melbourne.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "print(\"Variáveis Categóricas:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment',None)\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for col in object_cols:\n",
    "    label_encoder.fit(X_train[col])\n",
    "    X_train[col] = label_encoder.transform(X_train[col])    \n",
    "    X_valid[col] = label_encoder.transform(X_valid[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Normalização):\n",
      "323172.6316158428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "norm_X_train = X_train.copy()\n",
    "norm_X_valid = X_valid.copy()\n",
    "\n",
    "norm_numerical_cols = numerical_cols.copy()\n",
    "del norm_numerical_cols[1]\n",
    "\n",
    "for column in norm_numerical_cols:\n",
    "    transformer = Normalizer()\n",
    "    \n",
    "    values = np.array(norm_X_train[column]).reshape(-1,1)\n",
    "    norm_X_train[column] = transformer.fit_transform(values)\n",
    "    \n",
    "    values = np.array(norm_X_valid[column]).reshape(-1,1)\n",
    "    norm_X_valid[column] = transformer.transform(values)\n",
    "\n",
    "print(\"MAE from Approach 1 (Normalização):\")\n",
    "print(score_dataset(norm_X_train, norm_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Padronização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Padronização):\n",
      "165999.9143014938\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_X_train = X_train.copy()\n",
    "std_X_valid = X_valid.copy()\n",
    "\n",
    "std_numerical_cols = numerical_cols.copy()\n",
    "del std_numerical_cols[1]\n",
    "\n",
    "for column in std_numerical_cols:\n",
    "    transformer = StandardScaler()\n",
    "    \n",
    "    values = np.array(std_X_train[column]).reshape(-1,1)\n",
    "    std_X_train[column] = transformer.fit_transform(values)\n",
    "    \n",
    "    values = np.array(std_X_valid[column]).reshape(-1,1)\n",
    "    std_X_valid[column] = transformer.transform(values)\n",
    "\n",
    "print(\"MAE from Approach 2 (Padronização):\")\n",
    "print(score_dataset(std_X_train, std_X_valid, y_train, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
